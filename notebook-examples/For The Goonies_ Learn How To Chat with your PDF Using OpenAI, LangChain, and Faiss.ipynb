{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OZpmLgd5D_qmjTnL5AsD1_ZJDdb7LQZI","timestamp":1686353523572}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **For the Goonies: Learn How To Chat with your PDF Using OpenAI, LangChain, and Faiss**\n","From the [Blueprint Technologies](https://www.bpcs.com) LLM Center of Excellence.\n","\n","![The Goonies](https://i.gifer.com/4y4.gif)\n","\n","*This notebook assumes you know how to navigate a Google Colab notebook. If you need an overview, check [this](https://web.eecs.umich.edu/~justincj/teaching/eecs442/WI2021/colab.html) out.*\n","\n","*This notebook requires an OpenAI api key. You can get one via a free trial with OpenAI [here](https://platform.openai.com/account/api-keys).*\n","\n","This is a notebook for those that want to learn about working with LLM's. It's entirely self-contained and only requires you to upload your PDF to the Files on the left.\n","\n","![Example of uploading](https://miro.medium.com/v2/resize:fit:846/1*TYvbH2G9G6JtLUVlDsyp9w.png)\n","\n","\n","\n"],"metadata":{"id":"_x1GI7Fo8Y7x"}},{"cell_type":"markdown","source":["# I. The Adventure Starts Here\n","![It's our time down here](https://y.yarn.co/6d1f234b-cbcd-4fd3-8e4b-4c9aa62d64b3_text.gif)\n","\n","#### **Background**\n","It's time to install the packages and import the libraries needed. The main ones to be aware of:\n","- [LangChain](https://python.langchain.com/en/latest/index.html) - for chunking and creating our question/answer chain\n","- [Faiss](https://github.com/facebookresearch/faiss) - for similarity search and vector index\n","- [OpenAI](https://platform.openai.com/docs/models/overview) - for creating our embeddings and natural language interaction"],"metadata":{"id":"Q24Y-g6h-Bg0"}},{"cell_type":"markdown","source":["### Step 1: Install the packages we need"],"metadata":{"id":"z7FJA2XdguSq"}},{"cell_type":"code","source":["!pip install -q langchain pypdf pandas matplotlib tiktoken textract transformers openai faiss-cpu"],"metadata":{"id":"gk2J2sYYjTkM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 2: Import the libraries we need"],"metadata":{"id":"SHCAZ7KRhBtk"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from transformers import GPT2TokenizerFast\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.chains.question_answering import load_qa_chain\n","from langchain.llms import OpenAI\n","from langchain.chains import ConversationalRetrievalChain"],"metadata":{"id":"l-uszlwN641q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 3: Set your OpenAI api key"],"metadata":{"id":"bsIocEfkhTJc"}},{"cell_type":"code","source":["os.environ[\"OPENAI_API_KEY\"] = \"PASTE YOUR OPENAI API CODE HERE\""],"metadata":{"id":"E2Buv5Y0uFr8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# II. The Chunking\n","\n","![Truffle Shuffle](https://media0.giphy.com/media/GHcm2aWIczatG/200w.gif?cid=6c09b95282hparla8to2yq6klqeddy1xkorzztyimkupr7o7&ep=v1_gifs_search&rid=200w.gif&ct=g)\n","\n","\n","#### **Background**\n","Basically, chunking a file is breaking it up into tokens.\n","\n","![The basics of chunking](https://www.pinecone.io/images/chunking-doc.png)\n","\n","\n","#### **Terms**\n","- **Chunking**: process of extracting phrases from unstructured text by analyzing a sentence to identify constituents such as noun groups, verbs, verb groups, etc. [Read more](https://towardsdatascience.com/chunking-in-nlp-decoded-b4a71b2b4e24)\n","- **LangChain Documents**: a piece of text and optional metadata used to interact with the language model."],"metadata":{"id":"RLULMPXa-Hu8"}},{"cell_type":"code","source":["# Upload your PDF to this workspace Files folder.\n","\n","# That's right, make sure your PDF is uploaded. You should see it to the left under Files. I used the PDF of the whitepaper at https://www.cidrdb.org/cidr2023/papers/p92-jain.pdf."],"metadata":{"id":"4JRR3jMqdjPX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Update with name (no .pdf extension) of your PDF file\n","originalPDF = \"./p92-jain\"\n","\n","# Convert PDF to text\n","import textract\n","doc = textract.process(originalPDF + '.pdf')\n","\n","# Save text to .txt and reopen\n","with open(originalPDF + '.txt', 'w') as f:\n","    f.write(doc.decode('utf-8'))\n","\n","with open(originalPDF + '.txt', 'r') as f:\n","    text = f.read()\n","\n","# Count tokens using function from transformers imported earlier\n","tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n","\n","def count_tokens(text: str) -> int:\n","    return len(tokenizer.encode(text))\n","\n","# Split text into chunks via LangChain\n","text_splitter = RecursiveCharacterTextSplitter(\n","    # Set a really small chunk size.\n","    chunk_size = 512,\n","    chunk_overlap  = 24,\n","    length_function = count_tokens,\n",")\n","# Convert chunks into LangChain document objects\n","chunks = text_splitter.create_documents([text])\n","\n","# Result is LangChain documents objects with a token size around what you defined in chunk_size (LangChain's RecursiveCharacterTextSplitter sometimes allows more tokens to retain context)\n","print (\"Your pdf has been chunked into\", len(chunks), \"documents.\")"],"metadata":{"id":"iADY2CXNlNq9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's visualize The Chunking\n","\n","# Create list of token counts\n","token_counts = [count_tokens(chunk.page_content) for chunk in chunks]\n","\n","# Create a pandas DataFrame from the token counts\n","df = pd.DataFrame({'Token Count': token_counts})\n","\n","# Create a histogram of the token count distribution\n","df.hist(bins=40, )\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"fK31bxDOpz1l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# III. The Data\n","![Data on zipline](https://64.media.tumblr.com/2d5ffe083dd70a4c1660aa839774482e/tumblr_osppf6rYBe1r59rp1o5_r1_250.gif)\n","\n","#### **Background**\n","ML algorithms need numbers to work with. Vector embeddings are basically content (such as text chunks) converted/reduced into lists of numbers. Learn more about vector embeddings [here](https://www.pinecone.io/learn/vector-embeddings/)\n","\n","Specifically for our PDF chat, we have taken the PDF file and put it through The Chunking. Now we will convert those chunks into embeddings and store in a vector index.\n","\n","![](https://pbs.twimg.com/media/Ftb3YhiX0AMl5m8.jpg:large)\n","\n","#### **Terms**\n","- **Vector embeddings**:"],"metadata":{"id":"_IlznUDK-i2m"}},{"cell_type":"code","source":["# Generate embeddings using OpenAI embedding model\n","embeddings = OpenAIEmbeddings()"],"metadata":{"id":"92ObhTAKnZzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create Faiss vector index with our embeddings\n","db = FAISS.from_documents(chunks, embeddings)"],"metadata":{"id":"X13Pj5Cwp1Zz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# IV. The Ride\n","![Get on the bike](https://j.gifs.com/KYzMln.gif)\n","\n","Time to get rolling! Here we will test our similarity search using the embeddings created in the previous step and try out asking a question of our PDF using LangChain and OpenAI."],"metadata":{"id":"2LPwdGDP-nPO"}},{"cell_type":"code","source":["# Setup and check the Faiss similarity search of the PDF\n","query = \"What is the name of this?\"\n","docs = db.similarity_search(query)\n","docs[0]"],"metadata":{"id":"RWP92zGg5Nb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create question answering chain with LangChain and run it with Faiss similarity search\n","chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n","\n","# Now run it. If all goes well, you will see a more natural response to the query we set up.\n","chain.run(input_documents=docs, question=query)"],"metadata":{"id":"1Kv_sM8G5qAo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# V. The Mouth\n","![Mouth](https://64.media.tumblr.com/cc419bf2f758986e69dda3b4643bcfb8/tumblr_osmoo8EqYc1r59rp1o9_r2_250.gif)\n","\n","It has come down to this. We will be combining our vector index we created previously, with some LangChain and OpenAI goodness to create a chatbot. With this chatbot, we can continually ask questions of our PDF. The chatbot will even keep a history of the questions we ask."],"metadata":{"id":"U_nH1qoL-w--"}},{"cell_type":"code","source":["from IPython.display import display\n","import ipywidgets as widgets\n","\n","# Create a conversation chain that uses our vector index as retriver, this also allows for chat history management\n","qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), db.as_retriever())"],"metadata":{"id":"evF7_Dyhtcaf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chat_history = []\n","\n","def on_submit(_):\n","    query = input_box.value\n","    input_box.value = \"\"\n","\n","    if query.lower() == 'exit':\n","        print(\"Hey, if you find a 50 dollar bill, let me know...else, have a nice day.\")\n","        return\n","\n","    result = qa({\"question\": query, \"chat_history\": chat_history})\n","    chat_history.append((query, result['answer']))\n","\n","    display(widgets.HTML(f'<b>User:</b> {query}'))\n","    display(widgets.HTML(f'<b><font color=\"blue\">Data:</font></b> {result[\"answer\"]}'))\n","\n","print(\"Welcome to your PDF chatbot! Type 'exit' to stop.\")\n","\n","input_box = widgets.Text(placeholder='Enter your question:')\n","input_box.on_submit(on_submit)\n","\n","display(input_box)"],"metadata":{"id":"-pHw5siewPNt"},"execution_count":null,"outputs":[]}]}