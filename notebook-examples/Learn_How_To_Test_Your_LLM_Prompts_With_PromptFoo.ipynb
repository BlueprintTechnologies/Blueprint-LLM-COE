{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Learn How To Test Your LLM Prompts with PromptFoo**\n",
        "\n",
        "From the [Blueprint Technologies](https://www.bpcs.com) LLM Center of Excellence.\n",
        "\n",
        "![PromptFoo](https://cdn-images-1.medium.com/max/1600/0*3Wx-HCh5wMsDbp1F)\n",
        "\n",
        "A tool for testing LLM prompts. Available on Github at https://github.com/promptfoo/promptfoo\n",
        "\n",
        "## Scenario\n",
        "Imagine you are asked to start experimenting with creating a LLM powered chatbot for the game company that makes Grand Theft Auto 5. All content the chatbot should reference is available publicly, so you opt to leverage OpenAI as the LLM provider. Now you want to optimize your LLM prompts that deliver the most relevant information to the customer in a succinct yet understandable manner.\n",
        "\n",
        "## Persona\n",
        "This is a notebook for those that want to learn LLM prompt engineering testing using promptfoo. It's entirely self-contained.\n",
        "\n",
        "*This notebook assumes you know how to navigate a Google Colab notebook. If you need an overview, check [this](https://web.eecs.umich.edu/~justincj/teaching/eecs442/WI2021/colab.html) out.*\n",
        "\n",
        "*This notebook requires an OpenAI api key. You can get one via a free trial with OpenAI [here](https://platform.openai.com/account/api-keys).*\n",
        "\n"
      ],
      "metadata": {
        "id": "gAFLRZwkqVKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Node version\n",
        "# Node version 16 or higher is required for PromptFoo to work\n",
        "# The current version of Node in Google Colab is 14.16\n",
        "!node -v"
      ],
      "metadata": {
        "id": "IuFagAyOMbVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade to the latest version of Node.\n",
        "# I tried a few different approaches (such as the one recommended by debsource - https://deb.nodesource.com/).\n",
        "# I landed on using the the n package manager. Learn more at https://nodejs.org/en/download/package-manager#n\n",
        "!npm install -g n\n",
        "!n latest\n",
        "!node -v"
      ],
      "metadata": {
        "id": "QclaTB3MLwjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your OpenAI key\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-ABCDEF\""
      ],
      "metadata": {
        "id": "yelSoHIl2Wto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Set up promptfoo\n",
        " # This will create a base prompts.txt and promptfooconfig.yaml configuration in your workspace\n",
        "%env npm_config_yes=true\n",
        "!npx promptfoo init"
      ],
      "metadata": {
        "id": "uhT0g2Vqq5iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's adjust our prompts for our particular scenario. This will overwrite the base prompts.txt content.\n",
        "# Here you can see I'm testing two different prompt styles.\n",
        "%%writefile prompts.txt\n",
        "You're a customer support chat assistant for the video game company that makes Grand Theft Auto 5.\n",
        "Answer this user's question: {{name}}: \"{{question}}\"\n",
        "---\n",
        "You're a smart, bubbly customer support chat assistant for the video game company that makes Grand Theft Auto 5.\n",
        "Answer this user's question: {{name}}: \"{{question}}\""
      ],
      "metadata": {
        "id": "ykbXf3w-rPpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's set up our testing variables. This will overwrite the config in the promptfooconfig.yaml\n",
        "# For our scenario, I opted to pull frequently asked questions from IGN at https://www.ign.com/wikis/gta-5/Questions_and_Answers\n",
        "%%writefile promptfooconfig.yaml\n",
        "prompts: [prompts.txt]\n",
        "providers: [openai:chat:gpt-4-0613, openai:chat:gpt-3.5-turbo-16k-0613]\n",
        "tests:\n",
        "  - vars:\n",
        "      name: Memphis\n",
        "      question: How can I make my garage bigger to store more cars?\n",
        "  - vars:\n",
        "      name: XXX\n",
        "      question: Where can I base jump?\n",
        "  - vars:\n",
        "      name: Roger\n",
        "      question: Where can I find Packie?"
      ],
      "metadata": {
        "id": "5tCiNC5VrWBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, unleash the magic and run the evaluation\n",
        "!npx promptfoo eval -c /content/promptfooconfig.yaml --no-progress-bar"
      ],
      "metadata": {
        "id": "gp3OWyOAAsW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's take a look at the testing results in the web viewer (formatted for readability)\n",
        "# Because we are using Google Colab, will need to use the share option vs the view option\n",
        "!npx promptfoo share --yes"
      ],
      "metadata": {
        "id": "jUwMkZP_Pp9_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}